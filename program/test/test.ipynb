{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "# 行列形式のリンク情報をベクトル形式に変換する関数\n",
    "def trans_linkMat_to_linkVec(linkMat, init_incMat, term_incMat):\n",
    "\n",
    "    temp_linkMat = init_incMat.T @ linkMat @ term_incMat\n",
    "    linkVec = np.diag(temp_linkMat.toarray())\n",
    "\n",
    "    return linkVec\n",
    "\n",
    "# ベクトル形式のリンク情報を行列形式に変換する関数\n",
    "def trans_linkVec_to_linkMat(linkVec, init_incMat, term_incMat):\n",
    "\n",
    "    num_vec = linkVec.shape[0]\n",
    "    row = np.arange(num_vec)\n",
    "    col = np.arange(num_vec)\n",
    "\n",
    "    temp_linkMat = sparse.csr_matrix((linkVec, (row, col)))\n",
    "    linkMat = init_incMat @ temp_linkMat @ term_incMat.T\n",
    "\n",
    "    return linkMat\n",
    "\n",
    "# 重み行列（exp(-theta*link_cost)）作成\n",
    "def make_link_weight(cost_vec, theta):\n",
    "\n",
    "    link_weight = np.exp(-theta * cost_vec)\n",
    "\n",
    "    return link_weight\n",
    "\n",
    "# 期待最小費用行列を作成する関数(起点×目的のノード)\n",
    "def calc_expected_minCost_mat(weight_mat, conv_judge):\n",
    "\n",
    "    num_vec = weight_mat.shape[0]\n",
    "    data = np.ones(num_vec)\n",
    "    row = np.arange(num_vec)\n",
    "    col = np.arange(num_vec)\n",
    "\n",
    "    exp_minCost = sparse.csr_matrix((data, (row, col)))\n",
    "    temp_exp_minCost = exp_minCost.copy()\n",
    "\n",
    "    while np.max(temp_exp_minCost) > conv_judge:\n",
    "        temp_exp_minCost = temp_exp_minCost @ weight_mat\n",
    "        exp_minCost += temp_exp_minCost\n",
    "\n",
    "    return exp_minCost\n",
    "\n",
    "# 期待最小費用からリンクの条件付き選択確率を計算する関数\n",
    "def calc_choPer(weight_mat, exp_minCost, orig_node_id):\n",
    "\n",
    "    temp_minCost_vec = exp_minCost[orig_node_id, :]\n",
    "    data = temp_minCost_vec.data\n",
    "    row = temp_minCost_vec.indices\n",
    "    col = temp_minCost_vec.indices\n",
    "\n",
    "    temp_mat = sparse.csr_matrix((data, (row, col)), shape=weight_mat.shape)\n",
    "    per_nume = temp_mat @ weight_mat\n",
    "\n",
    "    # ここはもう少し効率化できそう\n",
    "    per_mat = np.divide(per_nume.toarray(), temp_minCost_vec.toarray(), out=np.zeros_like(per_nume.toarray()), where=temp_minCost_vec.toarray() != 0)\n",
    "    per_mat = sparse.csr_matrix(per_mat)\n",
    "\n",
    "    return per_mat\n",
    "\n",
    "# ノードフローを計算する関数(demandをスパース行列にすると早そう)\n",
    "def calc_nodeFlow(per_mat, demand):\n",
    "\n",
    "    num_vec = per_mat.shape[0]\n",
    "    data = np.ones(num_vec)\n",
    "    row_col = np.arange(num_vec)\n",
    "\n",
    "    node_per_mat = sparse.csr_matrix((data, (row_col, row_col)))\n",
    "    temp_per_mat = sparse.csr_matrix((data, (row_col, row_col)))\n",
    "\n",
    "    while np.max(temp_per_mat) > 0.0:\n",
    "        temp_per_mat = temp_per_mat @ per_mat\n",
    "        node_per_mat += temp_per_mat\n",
    "\n",
    "    nodeFlow = (node_per_mat @ demand.T).T\n",
    "\n",
    "    return nodeFlow\n",
    "\n",
    "# リンクフローを計算する関数\n",
    "def calc_linkFlow(per_mat, nodeFlow):\n",
    "    \n",
    "    # ここはもう少し速くできそう\n",
    "    linkFlow = np.multiply(nodeFlow.toarray(), per_mat.toarray())\n",
    "    linkFlow = sparse.csr_matrix(linkFlow)\n",
    "\n",
    "    return linkFlow\n",
    "\n",
    "# ロジット配分を計算する関数\n",
    "def LOGIT(cost_vec, tripsMat, init_incMat, term_incMat, theta, conv_judge=0.0):\n",
    "\n",
    "    link_weight = make_link_weight(cost_vec, theta)\n",
    "    weight_mat = trans_linkVec_to_linkMat(link_weight, init_incMat, term_incMat)\n",
    "    exp_minCost = calc_expected_minCost_mat(weight_mat, conv_judge)\n",
    "\n",
    "    total_link_flow = sparse.csr_matrix(([], ([], [])), shape=(init_incMat.shape[0], init_incMat.shape[0]))\n",
    "\n",
    "    for orig_node_id in range(tripsMat.shape[0]):\n",
    "\n",
    "        per_mat = calc_choPer(weight_mat, exp_minCost, orig_node_id)\n",
    "        node_flow = calc_nodeFlow(per_mat, tripsMat[orig_node_id])\n",
    "        link_flow = calc_linkFlow(per_mat, node_flow)\n",
    "        total_link_flow += link_flow\n",
    "\n",
    "    link_flow_vec = trans_linkMat_to_linkVec(total_link_flow, init_incMat, term_incMat)\n",
    "\n",
    "    return link_flow_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGIT_flow =  [ 3644.30763886  6268.66147458  3644.3076979   6381.01928116\n",
      "  6268.66141554  9008.87427442  8173.92719439  9008.84996707\n",
      " 14361.98608008  6955.37198879 14362.107923   10240.23812428\n",
      "  7771.08558638  6381.0193402  10240.34494612 17313.53317034\n",
      "  8646.85724327 13871.30810066 17313.64005121  8646.6610578\n",
      "   758.15450782 14102.98543314  7771.10060747   758.15247523\n",
      " 17134.13945043 17234.15243892 21548.13794086 14387.10410583\n",
      " 27041.23241263  1173.36075149  7055.22583852 21348.18588348\n",
      " 11462.20129985 14835.52861059  8173.9514427  11461.60872971\n",
      " 12762.73146146 12862.16313963 12132.44476692 14836.02297308\n",
      "  8785.54060993  8772.34152233 14486.31939792  8785.95597581\n",
      " 18042.60652303 23535.09766945 14102.89816113 27141.6268414\n",
      " 28042.53197111 13666.83226353  1173.7160765  28042.94362084\n",
      " 23650.56070985 13871.50428614 13766.72777057 10909.61496082\n",
      " 18042.37843892 23651.32768459  6960.85503312 10909.70665333\n",
      "  6961.39392375  4096.22475407  7510.56149398  4030.13615178\n",
      " 15312.97153055 11557.89265954 23534.95641154  7477.28067941\n",
      " 15336.90192084 10469.69607088  8772.42051894 10460.20438869\n",
      "  9771.23741839 12131.87644509 11467.87366696  9761.82473281]\n",
      "LOGIT_time =  4.234375\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import openmatrix as omx\n",
    "\n",
    "# !!=============================================================!!\n",
    "#   データの読み取り関数\n",
    "# !!=============================================================!!\n",
    "\n",
    "# function to read <NUMBER OF ZONES>\n",
    "def read_num_zones(netfile):\n",
    "\n",
    "    file_data = open(netfile)\n",
    "    num_zones = 0\n",
    "\n",
    "    for i in range(8):\n",
    "        line = file_data.readline()\n",
    "        if \"<NUMBER OF ZONES>\" in line:\n",
    "            num_zones = int(line.split('\\t')[0][17:])\n",
    "            # print(num_zones)\n",
    "\n",
    "    return num_zones\n",
    "\n",
    "# function to read <NUMBER OF NODES>\n",
    "def read_num_nodes(netfile):\n",
    "\n",
    "    file_data = open(netfile)\n",
    "    num_nodes = 0\n",
    "\n",
    "    for i in range(8):\n",
    "        line = file_data.readline()\n",
    "        if \"<NUMBER OF NODES>\" in line:\n",
    "            num_nodes = int(line.split('\\t')[0][17:])\n",
    "            # print(num_nodes)\n",
    "\n",
    "    return num_nodes\n",
    "\n",
    "# ネットワークデータを読み取る関数\n",
    "def read_net(netfile):\n",
    "\n",
    "    net = pd.read_csv(netfile, skiprows=8, sep='\\t')\n",
    "    trimmed = [s.strip().lower() for s in net.columns]\n",
    "    net.columns = trimmed\n",
    "\n",
    "    # And drop the silly first andlast columns\n",
    "    net.drop(['~', ';'], axis=1, inplace=True)\n",
    "\n",
    "    return net\n",
    "\n",
    "# OD需要を読み取る関数\n",
    "def read_trips(tripsfile):\n",
    "\n",
    "    f = open(tripsfile, 'r')\n",
    "    all_rows = f.read()\n",
    "    blocks = all_rows.split('Origin')[1:]\n",
    "    matrix = {}\n",
    "    for k in range(len(blocks)):\n",
    "        orig = blocks[k].split('\\n')\n",
    "        dests = orig[1:]\n",
    "        orig = int(orig[0])\n",
    "\n",
    "        d = [eval('{'+a.replace(';', ',').replace(' ', '') + '}')\n",
    "             for a in dests]\n",
    "        destinations = {}\n",
    "        for i in d:\n",
    "            destinations = {**destinations, **i}\n",
    "        matrix[orig] = destinations\n",
    "    zones = max(matrix.keys())\n",
    "    mat = np.zeros((zones, zones))\n",
    "    for i in range(zones):\n",
    "        for j in range(zones):\n",
    "            # We map values to a index i-1, as Numpy is base 0\n",
    "            mat[i, j] = matrix.get(i+1, {}).get(j+1, 0)\n",
    "\n",
    "    index = np.arange(zones) + 1\n",
    "\n",
    "    myfile = omx.open_file('demand.omx', 'w')\n",
    "    myfile['matrix'] = mat\n",
    "    myfile.create_mapping('taz', index)\n",
    "    myfile.close()\n",
    "\n",
    "    return matrix\n",
    "       \n",
    "# !!=============================================================!!\n",
    "#   データ形式の変換関数 (引数として使える形に)\n",
    "# !!=============================================================!!\n",
    "\n",
    "# tripsデータ（OD需要）を行列（起点ノード×全ノード）形式に変換する関数\n",
    "def make_tripsMat(trips, num_zones, num_nodes):\n",
    "    tripsMat = np.zeros((num_zones, num_nodes))\n",
    "    for orig_node in trips.keys():\n",
    "        for dest_node in trips[orig_node].keys():\n",
    "            tripsMat[orig_node-1, dest_node-1] = trips[orig_node][dest_node]\n",
    "    tripsMat = sparse.csr_matrix(tripsMat)\n",
    "    return tripsMat\n",
    "\n",
    "# 起点ノード×リンクの接続行列を作成する関数\n",
    "def make_init_incMat(links, num_nodes):\n",
    "    init_incMat = np.zeros((num_nodes, len(links)), dtype=int)\n",
    "    for index, link in links.iterrows():\n",
    "        init_incMat[int(link['init_node'])-1, index] = 1 \n",
    "    init_incMat = sparse.csr_matrix(init_incMat)\n",
    "    return init_incMat\n",
    "\n",
    "# 終点ノード×リンクの接続行列を作成する関数\n",
    "def make_term_incMat(links, num_nodes):\n",
    "    term_incMat = np.zeros((num_nodes, len(links)), dtype=int)\n",
    "    for index, link in links.iterrows():\n",
    "        term_incMat[int(link['term_node'])-1, index] = 1\n",
    "\n",
    "    term_incMat = sparse.csr_matrix(term_incMat)\n",
    "    return term_incMat\n",
    "\n",
    "# !!=============================================================!! \n",
    "#   LOGIT配分の実行\n",
    "# !!=============================================================!!\n",
    "\n",
    "# データの読み取り\n",
    "links = read_net('./SiouxFalls_net.tntp')\n",
    "trips = read_trips('./SiouxFalls_trips.tntp')\n",
    "num_zones = read_num_zones('./SiouxFalls_net.tntp')\n",
    "num_nodes= read_num_nodes('./SiouxFalls_net.tntp')\n",
    "# print(links)\n",
    "\n",
    "# リンクの接続情報を行列形式に変換\n",
    "init_incMat = make_init_incMat(links, num_nodes)\n",
    "term_incMat = make_term_incMat(links, num_nodes)\n",
    "# リンクコストをベクトル形式に変換\n",
    "costVec = np.array(links['free_flow_time'])\n",
    "# tripsを行列形式に変換\n",
    "tripsMat = make_tripsMat(trips, num_zones, num_nodes)\n",
    "\n",
    "# LOGIT配分を計算\n",
    "start_time = time.process_time()\n",
    "LOGIT_flow = LOGIT(costVec, tripsMat, init_incMat, term_incMat, theta=1.0, conv_judge=0.0)\n",
    "end_time = time.process_time()\n",
    "print('LOGIT_flow = ', LOGIT_flow)\n",
    "print('LOGIT_time = ', end_time - start_time)\n",
    "\n",
    "# pandas形式にしたいなら……\n",
    "# links['LOGIT_FLOW'] = LOGIT_flow\n",
    "# print('Links = ', links) \n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
